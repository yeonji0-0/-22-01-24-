{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoNp9d6EVApiBY2NJh27mc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonji0-0/Python-codes/blob/main/%EB%B9%85%EB%B6%84%EA%B8%B0%EC%8B%A4%EA%B8%B0_%EC%97%B0%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "jTs2zvcOTvUn",
        "outputId": "1d6695d9-2895-4e98-8539-16aa3ae27e5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-2dd0035e40c2>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    -- 테스트 분리,검증 / 매개변수 튜닝\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# 라이브러리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## 인코딩,정규화,스케일링\n",
        "from sklearn.prepocessing import LabelEncoder,OneHotEncoder,StandardScaler,MinMaxScaler\n",
        "## 테스트 분리,검증 / 매개변수 튜닝\n",
        "from sklearn.model_selection import train_test_split, GridSeacherCV\n",
        "## 통계 평가\n",
        "from sklearn.metrics import mean_absolute_Error, mean_Squared_error, mean_absolute_percentage_error,roc_auc_score\n",
        "                           ,accuracy_score,precision_score,recall_score\n",
        "## 머신러닝 알고리즘\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "fromsklearn.svm import SVR\n",
        "fromsklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "fromsklearn.tree import decisiontree\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "\n",
        "\n",
        "# 데이터 불러오기\n",
        " pd.read_csv('')\n",
        "\n",
        "#전처리\n",
        "## 빈칸 채우기\n",
        "df[\"Age\"].fillna(df[\"Age\"].mean(), inplace=True)\n",
        "df[\"Cabin\"].fillna(\"N\", inplace=True)\n",
        "df[\"Fare\"].fillna(0, inplace=True)\n",
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())\n",
        "\n",
        "##혹은 결측치 제거\n",
        "df[\"Age\"].dropna()\n",
        "\n",
        "##이상치 확인\n",
        "\n",
        "##인코딩하기\n",
        "le = LabelEncoder()\n",
        "le.fit(train['주구매상품'])\n",
        "label_encoded = le.transform(train['주구매상품'])\n",
        "train['주구매상품'] = label_encoded\n",
        "\n",
        "#머신러닝\n",
        "##x,y구별해주기\n",
        "x_train = train.drop('성별',axis=1)\n",
        "y_train = train['성별']\n",
        "\n",
        "#스케일링 하기\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train) ## fit은 test에 사용하지 말 것!\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "#하이퍼파라미터 최적화\n",
        "grid_params = {\n",
        "\t'n_estimators' : [10,50,100],\n",
        "\t'max_depth' : [4,5,6]\n",
        "}\n",
        "rf_cv = GridSearchCV(cv =5, estimator=model_rf,param_grid = grid_params, scoring =\"roc_auc\" )\n",
        "rf_cv.fit(x_train,y_train)\n",
        "\n",
        "print(rf_cv.best_params_)\n",
        "print(rf_cv.best_score_)\n",
        "\n",
        "#예측하기\n",
        "sex_pred = rf_cv.predict(test)\n",
        "print(sex_pred)\n",
        "\n",
        "#저장하기\n",
        "df = pd.DataFrame(sex_pred, columns = ['pred'])\n",
        "df.to_csv(\"result.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-84e7v8RXZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T1-1 이상치 찾기(IQR사용)\n",
        "데이터에서 IQR을 활용해 Fare컬럼의 이상치를 찾고, 이상치 데이터의 여성 수를 구하시오"
      ],
      "metadata": {
        "id": "VExfzdX2OanA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv('../input/titanic/train.csv')\n",
        "\n",
        "df['Fare'].describe()\n",
        "df['Fare'].isnull().sum()\n",
        "# IQR 구하기\n",
        "Q1 = df['Fare'].quantile(.25)\n",
        "Q3 = df['Fare'].quantile(.75)\n",
        "IQR = Q3 - Q1\n",
        "R1 = Q1 - 1.5*IQR\n",
        "R3 = Q3 + 1.5*IQR\n",
        "print(df[df['Fare']<R1]['Fare'].count())\n",
        "print(df[df['Fare']>R3]['Fare'].count())\n",
        "print(len(df[(df['Fare']>R3)&(df['Sex'] == 'female')]))"
      ],
      "metadata": {
        "id": "G2fgAYz-ZXv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T1-2\n",
        "- 데이터셋(basic1.csv)의 'f5' 컬럼을 기준으로 상위 10개의 데이터를 구하고,\n",
        "- 'f5'컬럼 10개 중 최소값으로 데이터를 대체한 후,\n",
        "- 'age'컬럼에서 80 이상인 데이터의'f5 컬럼 평균값 구하기"
      ],
      "metadata": {
        "id": "eTsRBo8sRZaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head()\n",
        "df['f5'].nlargest(10)\n",
        "'''\n",
        "# 다른방식) f5컬럼을 기준으로 내림차순 정렬\n",
        "df = df.sort_values('f5', ascending=False)\n",
        "df.head(10)\n",
        "'''\n",
        "a = df['f5'].nlargest(10).index\n",
        "for i in a:\n",
        "    df['f5'][i] =  df['f5'].nlargest(10).min()\n",
        "\n",
        "df[df['age']>=80]['f5'].mean()"
      ],
      "metadata": {
        "id": "42knHq8aZX9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T1-3\n",
        "- 데이터셋(basic1.csv)의 앞에서 순서대로 70% 데이터만 활용해서,\n",
        "- 'f1'컬럼 결측치를 중앙값으로 채우기 전후의 표준편차를 구하고\n",
        "- 두 표준편차 차이 계산하기"
      ],
      "metadata": {
        "id": "vTyQl2ZtaHp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "len(df)*0.7\n",
        "df = df.head(70)\n",
        "'''\n",
        "# 데이터 나누기 방법1\n",
        "data70 = df.iloc[:70]\n",
        "data30 = df.iloc[70:]\n",
        "\n",
        "# [심화학습] 데이터 나누기 방법2\n",
        "# data70, data30 = np.split(df, [int(.7*len(df))])\n",
        "\n",
        "# [심화학습] 데이터 나누기 방법3 (랜덤으로 샘플링하라고 했을 때!!)\n",
        "# data70 = df.sample(frac = 0.7)\n",
        "# data70 = df.drop(data70.index)\n",
        "\n",
        "data70.tail()\n",
        "'''\n",
        "df['f1'].isnull().sum()\n",
        "before = df['f1'].std()\n",
        "after = df['f1'].fillna(df['f1'].median()).std()\n",
        "print(before)\n",
        "print(after)\n",
        "print(before - after)"
      ],
      "metadata": {
        "id": "JPdDvLmfaKhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-4\n",
        "- 데이터셋(basic1.csv)의 'age'컬럼의 이상치를 더하시오!\n",
        "- 단, 평균으로부터 '표준편차*1.5'를 벗어나는 영역을 이상치라고 판단함"
      ],
      "metadata": {
        "id": "hpw2_5jleqzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "m = df['age'].mean()\n",
        "s = df['age'].std()\n",
        "outfit_1 = m + 1.5*s\n",
        "outfit_2 = m - 1.5*s\n",
        "df[(df['age']> outfit_1 ) | (df['age']< outfit_2)]['age'].sum()"
      ],
      "metadata": {
        "id": "hz07si2fetSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HJOHJpBMe17x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-5 이상치를 찾아라(소수점 나이)\n",
        "주어진 데이터에서 이상치(소수점 나이)를 찾고 올림, 내림, 버림(절사)했을때 3가지 이상치를 포함한\n",
        "'age' 평균을 모두 구한 다음 모두 더하여 출력하시오"
      ],
      "metadata": {
        "id": "URVlzfuxrtVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head()\n",
        "# 소수점 데이터 찾기\n",
        "df = df[(df['age']-np.floor(df['age']))!= 0]\n",
        "df\n",
        "# 이상치를 포함한 데이터 올림, 내림, 버림의 평균값\n",
        "\n",
        "# 올림\n",
        "m_ceil = np.ceil(df['age']).mean()\n",
        "\n",
        "# 내림\n",
        "m_floor = np.floor(df['age']).mean()\n",
        "\n",
        "# 버림\n",
        "m_trunc = np.trunc(df['age']).mean()\n",
        "\n",
        "m_ceil, m_floor, m_trunc\n",
        "\n",
        "# 평균값 더한 다음 출력\n",
        "\n",
        "print(m_ceil + m_floor + m_trunc)"
      ],
      "metadata": {
        "id": "Kd-iPCUwsj7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-6 결측치 처리(map활용)\n",
        "-  주어진 데이터에서 결측치가 80%이상 되는 컬럼은(변수는) 삭제하고, 80% 미만인 결측치가 있는 컬럼은 'city'별 중앙값으로 값을 대체하고 'f1'컬럼의 평균값을 출력하세요!"
      ],
      "metadata": {
        "id": "wd9Ndg__2YKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head()\n",
        "df.isnull().sum()\n",
        "for i in df.columns:\n",
        "    if df[i].isnull().sum() >= len(df)*0.8:\n",
        "        df.drop(i,axis=1, inplace=True)\n",
        "df\n",
        "'''\n",
        "# EDA - 결측비율 확인\n",
        "df.isnull().sum()/df.shape[0]\n",
        "'''\n",
        "df.groupby('city')['f1'].median()\n",
        "k = df.groupby('city')['f1'].median()[0]\n",
        "d = df.groupby('city')['f1'].median()[0]\n",
        "b = df.groupby('city')['f1'].median()[0]\n",
        "s = df.groupby('city')['f1'].median()[0]\n",
        "'''\n",
        "# 도시별 중앙값 계산\n",
        "s=df[df['city']=='서울']['f1'].median()\n",
        "k=df[df['city']=='경기']['f1'].median()\n",
        "b=df[df['city']=='부산']['f1'].median()\n",
        "d=df[df['city']=='대구']['f1'].median()\n",
        "'''\n",
        "# f1결측치 city별 중앙값으로 대체\n",
        "df['f1'] = df['f1'].fillna(df['city'].map({'서울':s,'경기':k,'부산':b,'대구':d}))"
      ],
      "metadata": {
        "id": "eEYJg_ey2caH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-7 왜도와 첨도 구하기\n",
        "-  주어진 데이터 중 train.csv에서 'SalePrice'컬럼의 왜도와 첨도를 구한 값과, 'SalePrice'컬럼을 스케일링(log1p)로 변환한 이후 왜도와 첨도를 구해 모두 더한 다음 소수점 2째자리까지 출력하시오"
      ],
      "metadata": {
        "id": "2V_O6QO19HQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\n",
        "df['SalePrice'].head()\n",
        "\n",
        "df['SalePrice'].hist()\n",
        "\n",
        "# 'SalePrice'컬럼 왜도와 첨도계산\n",
        "s1 = df['SalePrice'].skew()\n",
        "k1 = df['SalePrice'].kurt()\n",
        "print(\"왜도:\" ,s1)\n",
        "print(\"첨도:\", k1)\n",
        "# log1p 변환\n",
        "df['SalePrice'] = np.log1p(df['SalePrice'])\n",
        "s2 = df['SalePrice'].skew()\n",
        "k2 = df['SalePrice'].kurt()\n",
        "\n",
        "round(s1+k1+s2+k2,2)"
      ],
      "metadata": {
        "id": "bKqXxvvM9QB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-8 조건에 맞는 데이터 표준편차 구하기\n",
        "- 주어진 데이터 중 basic1.csv에서 'f4'컬럼 값이 'ENFJ'와 'INFP'인 'f1'의 표준편차 차이를 절대값으로 구하시오"
      ],
      "metadata": {
        "id": "WLDA0bny9w_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head()\n",
        "\n",
        "a = df[df['f4'] == 'ENFJ']['f1'].std()\n",
        "b = df[df['f4'] == 'INFP']['f1'].std()\n",
        "abs(a-b)"
      ],
      "metadata": {
        "id": "jFz38r4f9t-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-9 **결측치** 제거 및 그룹 합계에서 조건에 맞는 값 찾아 출력\n",
        "- 주어진 데이터 중 basic1.csv에서 'f1'컬럼 결측 데이터를 제거하고, 'city'와 'f2'을 기준으로 묶어 합계를 구하고, 'city가 경기이면서 f2가 0'인 조건에 만족하는 f1 값을 구하시오"
      ],
      "metadata": {
        "id": "-nim7SZTPZMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head()\n",
        "\n",
        "# f1컬럼 결측치 제거\n",
        "df = df[~df['f1'].isnull()]\n",
        "\n",
        "#합계\n",
        "df.groupby(['city','f2']).sum()\n",
        "#'city가 경기이면서 f2가 0'인 조건에 만족하는 f1\n",
        "df.groupby(['city','f2']).sum().iloc[0,2]\n",
        "#혹은\n",
        "df.groupby(['city','f2']).sum().iloc[0]['f1']"
      ],
      "metadata": {
        "id": "exDCllUSVhho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-10 값 변경 및 2개 이상의 조건\n",
        "'f4'컬럼의 값이 'ESFJ'인 데이터를 'ISFJ'로 대체하고, 'city'가 '경기'이면서 'f4'가 'ISFJ'인 데이터 중 'age'컬럼의 최대값을 출력하시오!"
      ],
      "metadata": {
        "id": "MrMEcrybbKnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head(2)\n",
        "\n",
        "df['f4'].replace('ESFJ','ISFJ', inplace=True)\n",
        "df[(df['city']=='경기') & (df['f4'] =='ISFJ')]['age'].max()"
      ],
      "metadata": {
        "id": "jPqTMuWfbPdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-11 누적합 그리고 보간(결측치 처리)\n",
        "주어진 데이터 셋에서 'f2' 컬럼이 1인 조건에 해당하는 데이터의 'f1'컬럼 누적합을 계산한다. 이때 발생하는 누적합 결측치는 바로 뒤의 값을 채우고, 누적합의 평균값을 출력한다. (단, 결측치 바로 뒤의 값이 없으면 다음에 나오는 값을 채워넣는다)"
      ],
      "metadata": {
        "id": "2Exfv20RbekE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head(2)\n",
        "\n",
        "# 조건에 따른 누적합\n",
        "df2 = df[df['f2']==1]['f1'].cumsum()\n",
        "df2\n",
        "\n",
        "# 결측치 처리 (뒤에 나오는 값으로 채움)\n",
        "df2 = df2.fillna(method = 'bfill')\n",
        "df2\n",
        "\n",
        "# 평균 출력\n",
        "print(df2.mean())"
      ],
      "metadata": {
        "id": "6QMWPlXIiLEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-11 수치형 변수 변환하기\n",
        "주어진 데이터에서 'f5'컬럼을 표준화(Standardization (Z-score Normalization))하고 그 중앙값을 구하시오"
      ],
      "metadata": {
        "id": "15Yh_pNAncNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head(2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "df['f5'] = scaler.fit_transform(df[['f5']])\n",
        "df['f5'].median()"
      ],
      "metadata": {
        "id": "MF-ZPE_Mnia9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-12 여-존슨과 박스-칵스 변환\n",
        "주어진 데이터에서 20세 이상인 데이터를 추출하고 'f1'컬럼을 결측치를 최빈값으로 채운 후, f1 컬럼의 여-존슨과 박스콕스 변환 값을 구하고, 두 값의 차이를 절대값으로 구한다음 모두 더해 소수점 둘째 자리까지 출력(반올림)하시오"
      ],
      "metadata": {
        "id": "ekZN-X2-v0_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import power_transform\n",
        "\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.head(5)\n",
        "\n",
        "#최빈값 대체하기\n",
        "import statistics\n",
        "\n",
        "a20 = df[df['age'] >= 20]\n",
        "a20['f1'].fillna(statistics.mode(a20['f1']),inplace=True)\n",
        "\n",
        "# 다른방법) 최빈값으로 'f1' 컬럼 결측치 대체\n",
        "print(\"결측치 처리 전: \\n\", df.isnull().sum())\n",
        "print(\"최빈값: \",df['f1'].mode()[0])\n",
        "df['f1'] = df['f1'].fillna(df['f1'].mode()[0])\n",
        "print(\"결측치 처리 후: \\n\", df.isnull().sum())\n",
        "\n",
        "# 'f1'데이터 여-존슨 yeo-johnson 값 구하기\n",
        "a20['y'] = power_transform(a20[['f1']],standardize=False) # method 디폴트 값은 여-존슨’yeo-johnson’\n",
        "print(a20['y'].head())\n",
        "\n",
        "# 'f1'데이터 박스-콕스 box-cox 값 구하기\n",
        "a20['b'] = power_transform(a20[['f1']], method='box-cox', standardize=False)\n",
        "print(a20['b'].head())\n",
        "'''\n",
        "## 박스콕스 방법2\n",
        "from scipy import stats\n",
        "x = stats.boxcox(df['f1'])\n",
        "'''\n",
        "\n",
        "#계산하기\n",
        "print(round(abs(a20['y'] - a20['b']).sum(),2))"
      ],
      "metadata": {
        "id": "IwdW6TFav6sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-13 상위 10개, 하위 10개 차이\n",
        " 주어진 데이터에서 상위 10개 국가의 접종률 평균과 하위 10개 국가의 접종률 평균을 구하고, 그 차이를 구해보세요\n",
        " (단, 100%가 넘는 접종률 제거, 소수 첫째자리까지 출력)\n"
      ],
      "metadata": {
        "id": "nG1417Ij9R1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"../input/covid-vaccination-vs-death/covid-vaccination-vs-death_ratio.csv\")\n",
        "print(df.head())\n",
        "\n",
        "t = df.groupby('country')['ratio'].max().sort_values(ascending=False).iloc[3:13].mean()\n",
        "d = df.groupby('country')['ratio'].min().sort_values().head(10).mean()\n",
        "print(round(t-d),1)"
      ],
      "metadata": {
        "id": "dAuEk8vQ9Xjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-14 상관관계 구하기\n",
        "주어진 데이터에서 상관관계를 구하고, quality와의 상관관계가 가장 큰 값과, 가장 작은 값을 구한 다음 더하시오!\n",
        " 단, quality와 quality 상관관계 제외, 소수점 둘째 자리까지 출력"
      ],
      "metadata": {
        "id": "1PqDvYu8EYrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv\")\n",
        "print(df.head())\n",
        "\n",
        "abs(df.corr(method = 'pearson')['quality']).sort_values()\n",
        "d = df.corr(method = 'pearson')['quality'].loc['residual sugar']\n",
        "t = df.corr(method = 'pearson')['quality'].sort_values()[-2]\n",
        "round((t+d),2)\n",
        "\n",
        "#다른방법)\n",
        "# 상관관계 구하기\n",
        "df_corr = df.corr()\n",
        "df_corr = df_corr[:-1] # quailiy-quailiy 상관관계 제거\n",
        "print(df_corr['quality'])\n",
        "\n",
        "# 상관관계가 가장 큰 값과 가장 작은 값 (절대값으로 확인)\n",
        "max_corr=abs(df.corr()['quality'][:-1]).max()  #0.47\n",
        "min_corr=abs(df.corr()['quality'][:-1]).min()   #0.013\n",
        "\n",
        "if max_corr not in df.corr()[['quality']][:-1].values:\n",
        "    max_corr=-max_corr\n",
        "if min_corr not in df.corr()[['quality']][:-1].values:\n",
        "    min_corr=-min_corr\n",
        "\n",
        "# 결과 출력\n",
        "ans=round(max_corr+min_corr,2)\n",
        "print(ans) # 0.49"
      ],
      "metadata": {
        "id": "SGwvA8qfEmnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-15 2개 조건에 따른 상위값\n",
        "city와 f4를 기준으로 f5의 평균값을 구한 다음, f5를 기준으로 상위 7개 값을 모두 더해 출력하시오 (소수점 둘째자리까지 출력)"
      ],
      "metadata": {
        "id": "L4qp9e-aCb4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "df.head()\n",
        "\n",
        "round(df.groupby(['city','f4'])['f5'].mean().sort_values(ascending=False).head(7).sum(),2)\n",
        "\n",
        "# 다른 방식) dataframe 전환 후 상위 7개 출력\n",
        "df = df.reset_index().sort_values('f5', ascending=False).head(7)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "NYwJPGJLCsa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-16 슬라이싱 & 조건\n",
        "주어진 데이터 셋에서 age컬럼 상위 20개의 데이터를 구한 다음\n",
        "f1의 결측치를 중앙값으로 채운다.\n",
        "그리고 f4가 ISFJ와 f5가 20 이상인\n",
        "f1의 평균값을 출력하시오!"
      ],
      "metadata": {
        "id": "R2Dizcc6C2V0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "\n",
        "df1 = df.sort_values(by = 'age',ascending = False).head(20)\n",
        "print(df1)\n",
        "# 나이 순(내림차순)으로 정렬하고 reset_index로 재정렬!\n",
        "df = df.sort_values('age', ascending=False).reset_index(drop=True)\n",
        "print(df)\n",
        "\n",
        "df1['f1'].fillna(df1['f1'].median(), inplace=True)\n",
        "print(df1)\n",
        "print(df1[(df1['f4']=='ISFJ') & (df['f5'] >= 20)]['f1'].mean())"
      ],
      "metadata": {
        "id": "Ca3TNIf1FU0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-17 분산\n",
        "주어진 데이터 셋에서 f2가 0값인 데이터를 age를 기준으로 오름차순 정렬하고\n",
        "앞에서 부터 20개의 데이터를 추출한 후\n",
        "f1 결측치(최소값)를 채우기 전과 후의 분산 차이를 계산하시오 (소수점 둘째 자리까지)"
      ],
      "metadata": {
        "id": "eEFPQu5-F4M_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "df\n",
        "\n",
        "df1 = df[df['f2'] == 0].sort_values(by ='age').head(20)\n",
        "a = df1['f1'].var()\n",
        "b = df1['f1'].fillna(df['f1'].min()).var()\n",
        "print(a,b)\n",
        "print(round(b-a,2))"
      ],
      "metadata": {
        "id": "Y0--j2qLW-sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-18 시계열 데이터\n",
        "2022년 5월 sales의 중앙값을 구하시오"
      ],
      "metadata": {
        "id": "_QoPS3YmXGsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\")\n",
        "\n",
        "# datetime으로 type변경\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.info()\n",
        "\n",
        "# 새로운 컬럼 추가 (년, 월, 일)\n",
        "df['year'] = df['Date'].dt.year\n",
        "df['month'] = df['Date'].dt.month\n",
        "df['day'] = df['Date'].dt.day\n",
        "df[(df['year'] == 2022)&(df['day'] == 5) ]['Sales'].median()"
      ],
      "metadata": {
        "id": "JDpZowlMZBGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-19 시계열 데이터\n",
        "주어진 데이터에서 2022년 5월 주말과 평일의 sales컬럼 평균값 차이를 구하시오 (소수점 둘째자리까지 출력, 반올림)"
      ],
      "metadata": {
        "id": "7IGy6vxxZJao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "# 데이터 불러오기 (datatime컬럼 지정)\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\", parse_dates=['Date'])\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['year'] = df['Date'].dt.year\n",
        "df['month'] = df['Date'].dt.month\n",
        "df['day'] = df['Date'].dt.day\n",
        "df['week'] = df['Date'].dt.dayofweek\n",
        "# 주말인지 아닌지 확인하는 추가적인 방법\n",
        "df['weekend'] = df['dayofweek'].apply(lambda x: x>=5)\n",
        "\n",
        "\n",
        "a = df[(df['year'] == 2022) & (df['month'] == 5) & (df['week'] < 5)]['Sales'].mean()\n",
        "b = df[(df['year'] == 2022) & (df['month'] == 5) & (df['week'] >= 5)]['Sales'].mean()\n",
        "# 다른 방법\n",
        "weekday_cond = (df['year']==2022) & (df['month']==5) & (~df['weekend'])\n",
        "\n",
        "\n",
        "print(round(b-a),2)\n",
        "\n"
      ],
      "metadata": {
        "id": "LFuPBr_Oc0MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-20 시계열 데이터3\n",
        "주어진 데이터에서 2022년 월별 Sales 합계 중 가장 큰 금액과\n",
        "2023년 월별 Sales 합계 중 가장 큰 금액의 차이를 절대값으로 구하시오.\n",
        "단 Events컬럼이 '1'인경우 80%의 Salse값만 반영함\n",
        "(최종값은 소수점 반올림 후 정수 출력)"
      ],
      "metadata": {
        "id": "-KWH_3OzdSVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "# 데이터 불러오기 (datatime컬럼 지정)\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\",\n",
        "                 parse_dates=['Date'])\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['year'] = df['Date'].dt.year\n",
        "df['month'] = df['Date'].dt.month\n",
        "df['day'] = df['Date'].dt.day\n",
        "\n",
        "for i in range(len(df)):\n",
        "    if df['Events'][i]== 1:\n",
        "        df['Events'][i] = df['Sales'][i]*0.8\n",
        "\n",
        "# 다른방식) 이벤트가 1인 sales값은 80%만 반영\n",
        "def event_sales(x):\n",
        "    if x['Events'] == 1:\n",
        "        x['Sales2'] = x['Sales']*0.8\n",
        "    else:\n",
        "        x['Sales2'] = x['Sales']\n",
        "    return x\n",
        "df = df.apply(lambda x: event_sales(x), axis=1) #1일 경우 row, 0일 경우 컬럼\n",
        "df.head()\n",
        "\n",
        "m_2022 = df[df['year'] == 2022].groupby(by = 'month').sum()['Sales'].max()\n",
        "m_2023 = df[df['year'] == 2023].groupby(by = 'month').sum()['Sales'].max()\n",
        "# 결과값 반올림 후 정수 출력\n",
        "int(round(abs(m_2022 - m_2023),0))\n",
        "\n"
      ],
      "metadata": {
        "id": "7ppgBNRtg--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T-21 데이터 병합\n",
        "basic1 데이터와 basic3 데이터를 'f4'값을 기준으로 병합하고,\n",
        "병합한 데이터에서 r2결측치를 제거한다음, 앞에서 부터 20개 데이터를 선택하고 'f2'컬럼 합을 구하시오"
      ],
      "metadata": {
        "id": "a0Gr6MrA0sNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 및 데이터 로드\n",
        "import pandas as pd\n",
        "b1 = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "b3 = pd.read_csv(\"../input/bigdatacertificationkr/basic3.csv\")\n",
        "\n",
        "df= pd.merge(b1,b3, on ='f4' )\n",
        "# 다른방법) 데이터 결합(b1을 기준으로 결합)\n",
        "df = pd.merge(left = b1 , right = b3, how = \"left\", on = \"f4\")\n",
        "\n",
        "\n",
        "df['r2'].dropna()\n",
        "#다른 방법) r2컬럼 결측치 제거\n",
        "print(df.shape)\n",
        "df = df.dropna(subset=['r2'])\n",
        "# 인덱스 리셋\n",
        "df = df.reset_index()\n",
        "\n",
        "\n",
        "df.iloc[:20,4].sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "dpYhzT0M2COq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-22 구간 분할\n",
        "나이 구간 나누기\n",
        "basic1 데이터 중 'age'컬럼 이상치를 제거하고, 동일한 개수로 나이 순으로 3그룹으로 나눈 뒤 각 그룹의 중앙값을 더하시오\n",
        "(이상치는 음수(0포함), 소수점 값)"
      ],
      "metadata": {
        "id": "qPwo4y-F93At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "\n",
        "df['age'].describe()\n",
        "df = df[df['age'] > 0 ]\n",
        "import numpy as np\n",
        "df = df[(np.ceil(df['age']) - df['age']) == 0]\n",
        "# df = df[df['age'] == round(df['age'],0)]\n",
        "\n",
        "# 구간 분할\n",
        "df['range'] = pd.qcut(df['age'], q = 3, labels=['group1','group2','group3'])\n",
        "# 수량 비교\n",
        "df['range'].value_counts()\n",
        "a = df[df['range'] == 'group1']['age'].median()\n",
        "b = df[df['range'] == 'group2']['age'].median()\n",
        "c = df[df['range'] == 'group3']['age'].median()\n",
        "print(a+b+c)"
      ],
      "metadata": {
        "id": "jAQJs1rw98Kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-23 time series\n",
        "주어진 데이터(basic2.csv)에서 주 단위 Sales의 합계를 구하고, 가장 큰 값을 가진 주와 작은 값을 가진 주의 차이를 구하시오(절대값)"
      ],
      "metadata": {
        "id": "H-B-tY3J-Im9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\", parse_dates=['Date'], index_col=0)\n",
        "\n",
        "# 아래 코드를 한줄로 표현함\n",
        "# df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\")\n",
        "# df['Date'] = pd.to_datetime(df['Date'])\n",
        "# df = df.set_index('Date')\n",
        "\n",
        "df_w = df.resample('W').sum() # .first() .last() 첫번째행이나 마지막행 가져오기\n",
        "abs(df_w['Sales'].max() - df_w['Sales'].min())\n",
        "\n",
        "##단위\n",
        "*분 단위 : T\n",
        "*시간 단위 : H\n",
        "*주 단위 : W\n",
        "*월 단위 : M\n",
        "*년 단위 : Y\n",
        "*10년 단위 : 10Y"
      ],
      "metadata": {
        "id": "4-8WjA7JA2uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-24 중복 데이터 제거\n",
        "f1의 결측치를 채운 후 age 컬럼의 중복 제거 전과 후의 'f1' 중앙값 차이를 구하시오\n",
        "- 결측치는 f1의 데이터 중 내림차순 정렬 후 10번째 값으로 채움\n",
        "- 중복 데이터 발생시 뒤에 나오는 데이터를 삭제함\n",
        "- 최종 결과값은 절대값으로 출력"
      ],
      "metadata": {
        "id": "8hYxceV8BYwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('../input/bigdatacertificationkr/basic1.csv')\n",
        "df.tail()\n",
        "\n",
        "df = df.sort_values(by='f1',ascending=False)\n",
        "f1_10 = df.iloc[9,3]\n",
        "df['f1'].fillna(f1_10, inplace=True)\n",
        "\n",
        "# f1데이터에서 10번째 큰 값으로 결측치를 채움\n",
        "top10 = df['f1'].sort_values(ascending=False).iloc[9]\n",
        "print(top10)\n",
        "df['f1'] = df['f1'].fillna(top10)\n",
        "\n",
        "b = df['f1'].median()\n",
        "df = df.drop_duplicates(subset=['age'])\n",
        "a = df['f1'].median()\n",
        "abs(b-a)"
      ],
      "metadata": {
        "id": "MakUNwiafjxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-25 시차 데이터 생성\n",
        "주어진 데이터(basic2.csv)에서 \"pv\"컬럼으로 1일 시차(lag)가 있는 새로운 컬럼을 만들고(예: 1월 2일에는 1월 1일 pv데이터를 넣고, 1월 3일에는 1월 2일 pv데이터를 넣음),새로운 컬럼의 1월 1일은 다음날(1월 2일)데이터로 결측치를 채운 다음, Events가 1이면서 Sales가 1000000이하인 조건에 맞는 새로운 컬럼 합을 구하시오"
      ],
      "metadata": {
        "id": "oebDzbLff0QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic2.csv\")\n",
        "df\n",
        "\n",
        "df['lag'] = 0\n",
        "\n",
        "for i in range(1,len(df)):\n",
        "    df['lag'][i] = df['PV'][i-1]\n",
        "    df['lag'][0] = df['lag'][1]\n",
        "df\n",
        "print(df[(df['Events'] ==1) & (df['Sales'] <= 1000000)]['lag'].sum())\n",
        "\n",
        "#다른 방식)\n",
        "#1일 차이가 나는 시차 특성 만들기\n",
        "df['previous_PV'] = df['PV'].shift(1)\n",
        "df.head()\n",
        "# 1일 씩 미뤘음으로 가장 앞이 결측값이 됨 (바로 뒤의 값으로 채움)\n",
        "df['previous_PV'] = df['previous_PV'].fillna(method = 'bfill')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gjZa6o9xiTAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-26 str_slicing\n",
        "basic1 데이터에서 f4가 E로 시작하면서 부산에 살고 20대인 사람은 몇 명?"
      ],
      "metadata": {
        "id": "GtEpBlFnirvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "df\n",
        "\n",
        "a = []\n",
        "for i in range(len(df)):\n",
        "    if df['f4'][i].count('E') >= 1:\n",
        "        a.append(i)\n",
        "df_e = df.loc[a,:]\n",
        "len(df_e[(df_e['city'] == '부산') & (df_e['age'] >= 20 )& (df_e['age'] < 30)])\n",
        "\n",
        "#다른방식\n",
        "df['EI'] = df['f4'].str[:1]\n",
        "cond1 = df['EI'] == \"E\"\n",
        "cond2 = df['city'] == \"부산\"\n",
        "cond3 = (df['age'] >= 20) & (df['age'] < 30)\n",
        "print(len(df[cond1 & cond2 & cond3]))\n"
      ],
      "metadata": {
        "id": "1lTHkPognNpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-27 str_contains\n",
        " menu컬럼에 \"라떼\" 키워드가 있는 데이터의 수는?"
      ],
      "metadata": {
        "id": "ad1fcyugWvf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/payment.csv\")\n",
        "df\n",
        "a = 0\n",
        "for i in range(len(df)):\n",
        "    if df['menu'][i].count('라떼') >= 1:\n",
        "          a += 1\n",
        " a\n",
        "# your code\n",
        "print(sum(df['menu'].str.contains(\"라떼\")))"
      ],
      "metadata": {
        "id": "66UziZ44WvpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-28 str_contains_replace\n",
        "바닐라라떼 5점, 카페라떼 3점, 아메리카노 2점, 나머지 0점이다 총 메뉴의 점수를 더한 값은?"
      ],
      "metadata": {
        "id": "CwPj_Xw6Wvw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/payment.csv\")\n",
        "df\n",
        "\n",
        "# 띄어쓰기 없애주는 과정 필요\n",
        "df['menu'] = df['menu'].str.replace(' ','')\n",
        "\n",
        "df['score'] = 0\n",
        "for i in range(len(df)):\n",
        "    if df['menu'][i].count('바닐라라떼') == 1:\n",
        "        df['score'] = 5\n",
        "    elif df['menu'][i].count('카페라떼') == 1:\n",
        "          df['score'] = 3\n",
        "    elif df['menu'][i].count('아메리카노') == 1:\n",
        "          df['score'] = 2\n",
        "    else:\n",
        "          df['score'] = 0\n",
        "df['score'].sum()\n",
        "\n",
        "#다른방식\n",
        "s1 = sum(df['menu'].str.contains(\"바닐라라떼\"))\n",
        "s2 = sum(df['menu'].str.contains(\"카페라떼\"))\n",
        "s3 = sum(df['menu'].str.contains(\"아메리카노\"))\n",
        "print((s1*5) + (s2*3) + (s3*2))\n"
      ],
      "metadata": {
        "id": "2vlM0i1VWv5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-28 value_counts_index\n",
        "시간(hour)이 13시 이전(13시 포함하지 않음) 데이터 중 가장 많은 결제가 이루어진 날짜(date)는? (date 컬럼과 동일한 양식으로 출력)"
      ],
      "metadata": {
        "id": "swxx1XJ-WwAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/payment.csv\")\n",
        "df\n",
        "\n",
        "df[df['hour'] < 13 ]['date'].value_counts().index[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "CMNQ-sE8WwIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-29 datetime-format\n",
        "12월인 데이터 수는?"
      ],
      "metadata": {
        "id": "__UZQwShWwQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/payment.csv\")\n",
        "df\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], format = '%Y%m%d')\n",
        "(df['date'].dt.month == 12).sum()"
      ],
      "metadata": {
        "id": "SkWUeHAEWwY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-30 datetime-percent\n",
        "12월 25일 결제 금액(price)은 12월 총 결제금액의 몇 %인가? (정수로 출력)"
      ],
      "metadata": {
        "id": "NPHyXz52WwfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/payment.csv\")\n",
        "df\n",
        "\n",
        "df['date'] = pd.to_datetime(df['date'], format = '%Y%m%d')\n",
        "int((df[(df['date'].dt.month == 12) & (df['date'].dt.day == 25)]['price'].sum()) / (df[df['date'].dt.month == 12 ]['price'].sum())*100)"
      ],
      "metadata": {
        "id": "tCgMmmEGWwmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-31 melt\n",
        "수학, 영어, 국어 점수 중 사람과 과목에 상관없이 가장 상위 점수 5개를 모두 더하고 출력하시오"
      ],
      "metadata": {
        "id": "acDtxl74Wwta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'Name': {0: '김딴짓', 1: '박분기', 2: '이퇴근'},\n",
        "                   '수학': {0: 90, 1: 93, 2: 85},\n",
        "                   '영어': {0: 92, 1: 84, 2: 86},\n",
        "                   '국어': {0: 91, 1: 94, 2: 83},})\n",
        "\n",
        "df\n",
        "\n",
        "df1 = pd.melt(df, id_vars = 'Name')\n",
        "sum(df1['value'].sort_values(ascending = False).head(5))"
      ],
      "metadata": {
        "id": "vPWssJhCWw0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-32 melt2\n",
        "수학, 영어 점수 중 사람과 과목에 상관없이 90점 이상인 점수의 평균을 정수로 구하시오 (소수점 버림)"
      ],
      "metadata": {
        "id": "FeHyZSGFWw6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({'Name': {0: '김딴짓', 1: '박분기', 2: '이퇴근'},\n",
        "                   '수학': {0: 90, 1: 93, 2: 85},\n",
        "                   '영어': {0: 92, 1: 84, 2: 86},\n",
        "                   '국어': {0: 91, 1: 94, 2: 83},})\n",
        "\n",
        "df\n",
        "\n",
        "df1 = pd.melt(df, id_vars = 'Name', value_vars = ['수학','영어'])\n",
        "int(df1[df1['value'] >= 90 ].mean())"
      ],
      "metadata": {
        "id": "4W1HTmBtWxCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-33 sigmoid\n",
        " basic1 데이터에서 f2 값에 시그모이드 함수(그림 내 수식)를 적용하고, f4가 ISFJ인 (변경된)f2의 합을 구하시오! (소수점 둘째자리까지 출력, 반올림)"
      ],
      "metadata": {
        "id": "nbX0aQNGWxJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "df\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "df['sigmoid_f2'] = sigmoid(df['f2'])\n",
        "#다른방식\n",
        "df['f2_sigmoid'] = df['f2'].apply(sigmoid)\n",
        "\n",
        "\n",
        "round(df[df['f4'] == 'ISFJ']['sigmoid_f2'].sum(),2)"
      ],
      "metadata": {
        "id": "iRRRAkNKWxQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-34 relu\n",
        "데이터에서 age 값에 ReLU 함수를 적용하고, city가 부산인 (변경된)age의 평균을 구하시오! (소수점 둘째자리까지 출력, 절사)"
      ],
      "metadata": {
        "id": "2-lewGtWeVFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"../input/bigdatacertificationkr/basic1.csv\")\n",
        "df\n",
        "\n",
        "def relu(x):\n",
        "  if x > 0:\n",
        "    return x\n",
        "  elif x <= 0:\n",
        "    return 0\n",
        "#다른방식\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "df['age'] = df['age'].apply(relu)\n",
        "round(df[df['city'] == '부산']['age'].mean(),2)\n"
      ],
      "metadata": {
        "id": "BuNmxQR-eVK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T1-35 작업형1 예시문제\n",
        "자동차 데이터 셋에서 qsec 컬럼을 Min-Max Scale로 변환 후 0.5보다 큰 값을 가지는 레코드(row) 수를 묻는 문제입니다\n"
      ],
      "metadata": {
        "id": "KRyYi_l0h239"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('../input/mtcars/mtcars.csv')\n",
        "data\n",
        "\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "data['qsec'] = minmax_scale(data['qsec'])\n",
        "len(data[data['qsec'] > 0.5])\n",
        "\n",
        "\n",
        "# 다른 방법1)\n",
        "# min-max scale\n",
        "data['qsec'] = minmax_scale(data['qsec'])\n",
        "print('minmax 변환 후: \\n',data['qsec'].head())\n",
        "\n",
        "# 0.5보다 큰 값 / 방법1,2 중에 선택\n",
        "print(sum(data['qsec'] > 0.5)) #방법1 (True를 더 함)\n",
        "print(len(data[data['qsec']>0.5])) #방법2 (데이터 수를 구함)\n",
        "\n",
        "\n",
        "#다른 방법2)\n",
        "# min-max scale\n",
        "def minmax(data):\n",
        "    data = (data - min(data)) / (max(data) - min(data))\n",
        "    return data\n",
        "\n",
        "data['qsec'] = minmax(data['qsec'])\n",
        "print('minmax 변환 후: \\n',data['qsec'].head())\n",
        "\n",
        "# 0.5보다 큰 값 (row 수 파악)\n",
        "print(len(data[data['qsec']>0.5]))"
      ],
      "metadata": {
        "id": "PdUPBBmYh3Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w7UuR59Xh3HN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UzpFpVfch3N0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-2 피마 인디언 당뇨병\n",
        "당뇨병 여부 파악 - 이상치 처리 (Glucose, BloodPressure, SkinThickness, Insulin, BMI가 0인 값)\n",
        "* 아래 코드 예측변수와 수험번호를 개인별로 변경하여 활용\n",
        "*pd.DataFrame({'cust_id': X_test.cust_id, 'gender': pred}).to_csv('003000000.csv', index=False)\n"
      ],
      "metadata": {
        "id": "CR-bGEZ4h3Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"../input/pima-indians-diabetes-database/diabetes.csv\")\n",
        "X_train, X_test, y_train, y_test = exam_data_load(df, target='Outcome')\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "a = X_train[X_train.loc[:,features] != 0][features].dropna()\n",
        "b = X_train.drop(features, axis=1)   #이상치 0인것 다 삭제\n",
        "X_train = pd.merge(a, b, how = 'left', left_index = True, right_index = True)\n",
        "X_train\n",
        "\n",
        "## 이상치 삭제가 아니라 평균값으로 대체한 방식 (포도당만 삭제)\n",
        "# 포도당 이상치 삭제\n",
        "del_idx = X_train[(X_train['Glucose']==0)].index\n",
        "del_idx\n",
        "# 포도당을 제외한 이상치, 평균값으로 대체\n",
        "cols = ['BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "cols_mean = X_train[cols].mean()\n",
        "X_train[cols].replace(0, cols_mean)\n",
        "\n",
        "\n",
        "y = pd.merge(X_train, y_train, how = 'left', on = 'id')\n",
        "y_train = y[['id','Outcome']]    #바로 컬럼명으로 쓸거면 이중 대괄호\n",
        "\n",
        "# id 제외\n",
        "X_train = X_train.drop('id',axis=1)\n",
        "X_test = X_test.drop('id',axis=1)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "cols = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']\n",
        "X_train[cols] = ss.fit_transform(X_train[cols])\n",
        "X_test[cols] = ss.transform(X_test[cols])\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, y_train['Outcome'])\n",
        "predicted_rf = model_rf.predict(X_test)\n",
        "\n",
        "#결과값 도출\n",
        "output = pd.DataFrame({'idx' : X_test.index, 'Outcome' : predicted_rf})\n",
        "output.head()\n",
        "\n",
        "# 수험번호.csv로 출력\n",
        "output.to_csv('1234567.csv', index=False)\n",
        "\n",
        "# 대략적인 점수 확인\n",
        "round(model_rf.score(X, y_train['Outcome']) * 100, 2)"
      ],
      "metadata": {
        "id": "7VQGkO1ih3bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-3 Adult Census Income\n",
        "성인 인구조사 소득 예측"
      ],
      "metadata": {
        "id": "NAyzDoBmh3hU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum()\n",
        "X_train.fillna('no', inplace=True)\n",
        "X_test.fillna('no', inplace=True)\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "features = ['workclass','education','marital.status','occupation','relationship','race','sex','native.country']\n",
        "for i in features:\n",
        "    le = LabelEncoder()\n",
        "    X_train[i] = le.fit_transform(X_train[i])\n",
        "    X_test[i] = le.transform(X_test[i])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train['income'] = le.fit_transform(y_train['income'])\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "cols = X_train.columns\n",
        "X_train[cols] = scaler.fit_transform(X_train[cols])\n",
        "X_test[cols] = scaler.transform(X_test[cols])\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "model_xgb = XGBClassifier()\n",
        "model_xgb.fit(X_train, y_train['income'])\n",
        "\n",
        "#validation 평가\n",
        "# 학습용 데이터와 검증용 데이터로 구분\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train['income'], test_size=0.15, random_state=2021)\n",
        "X_tr.shape, X_val.shape, y_tr.shape, y_val.shape\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "model_dt = DecisionTreeClassifier(random_state = 2022)\n",
        "model_dt.fit(X_tr, y_tr)\n",
        "pred = model_dt.predict(X_val)\n",
        "print('accuracy score:', (accuracy_score(y_val, pred)))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model_rf = RandomForestClassifier(random_state = 2022)\n",
        "model_rf.fit(X_tr, y_tr)\n",
        "pred = model_rf.predict(X_val)\n",
        "print('accuracy score:', (accuracy_score(y_val, pred)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "predicted_xgb = model_xgb.predict(X_test)\n",
        "\n",
        "output = pd.DataFrame({'idx' : X_test.index, 'income' : predicted_xgb})\n",
        "print(output)"
      ],
      "metadata": {
        "id": "QxYToUjyh3nU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-4 House Prices\n",
        "집값 예측"
      ],
      "metadata": {
        "id": "hzCJL-e3h3tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "for i in X_train.columns:\n",
        "    if (X_train.loc[:,i].isnull().sum()) > 500:\n",
        "        a.append(i)\n",
        "    else:\n",
        "        X_train.loc[:,i].fillna((X_train.loc[:,i].value_counts().iloc[:1].index[0]),inplace = True )\n",
        "\n",
        "\n",
        "for i in X_train.columns:\n",
        "    if (X_train.loc[:,i].value_counts().iloc[:1].iloc[0]) > 1000 :\n",
        "        a.append(i)\n",
        "X_train.drop(list(set(a)), axis=1, inplace=True)\n",
        "X_test.drop(list(set(a)), axis=1, inplace=True)\n",
        "X_train\n",
        "\n",
        "for i in X_test.columns:\n",
        "    X_test.loc[:,i].fillna((X_test.loc[:,i].value_counts().iloc[:1].index[0]),inplace = True )\n",
        "\n",
        "# na 대표값으로 채우기\n",
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer()\n",
        "X_train = imp.fit_transform(X_train)\n",
        "X_test = imp.transform(X_test)\n",
        "\n",
        "# 숫자만 남기는 방법\n",
        "X_train = X_train.select_dtypes(exclude=['object'])\n",
        "X_test = X_test.select_dtypes(exclude=['object'])\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols= []\n",
        "for i in X_train.columns:\n",
        "    if type(X_train.loc[0,i]) == str:\n",
        "         cols.append(i)\n",
        "\n",
        "for i in cols:\n",
        "    le = LabelEncoder()\n",
        "    X_train[i] = le.fit_transform(X_train[i])\n",
        "    X_test[i] = le.fit_transform(X_test[i])\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train['SalePrice'], test_size=0.15, random_state=20222)\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(X_tr, y_tr)\n",
        "pred = model.predict(X_val)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def rmsle(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "print(\"RMSLE : \" + str(rmsle(y_val, pred)))\n",
        "\n",
        "pred = model_xgb.predict(X_test)\n",
        "output = pd.DataFrame({'id': X_test['id'], 'SalePrice' : pred})\n",
        "output.to_csv('00000.csv', index = False)"
      ],
      "metadata": {
        "id": "YzaylnSth3y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-5  Insurance Forecast"
      ],
      "metadata": {
        "id": "efZRs3sWh35m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.isnull().sum()\n",
        "cols = []\n",
        "for i in X_train.columns:\n",
        "    if type(X_train.loc[0,i]) == str:\n",
        "        cols.append(i)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for i in cols:\n",
        "    le = LabelEncoder()\n",
        "    X_train[i] = le.fit_transform(X_train[i])\n",
        "    X_test[i] = le.transform(X_test[i])\n",
        "\n",
        "X_train\n",
        "\n",
        "# 나이를 10대, 20대, 30대로 구분하기 위해 10을 나눈 몫 값만 구함\n",
        "X_train['age'] = X_train['age'].apply(lambda x: x//10)\n",
        "X_test['age'] = X_test['age'].apply(lambda x: x//10)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train['charges'], test_size = 0.2, random_state= 1234)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rf = RandomForestRegressor()\n",
        "model_rf.fit(X_tr,y_tr)\n",
        "pred = model_rf.predict(X_val)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def rmsle(y,y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "rmsle(y_val, pred)\n",
        "\n",
        "pred = model_rf(X_test)\n",
        "output = pd.DataFrame({'id' : X_test['id'], 'charges' : pred})\n",
        "output.to_csv('ooooooo.csv', index =False)"
      ],
      "metadata": {
        "id": "WrNLRaQlh4An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T2-6 Bike-sharing-demand\n",
        "매 시간마다 렌탈된 자전거 수량 예측"
      ],
      "metadata": {
        "id": "Lbgkv9tjh4Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = X_train['count']\n",
        "\n",
        "\n",
        "X_train['month'] = pd.to_datetime(X_train['datetime']).dt.month\n",
        "X_train['hour'] = pd.to_datetime(X_train['datetime']).dt.hour\n",
        "X_train\n",
        "X_test['month'] = pd.to_datetime(X_test['datetime']).dt.month\n",
        "X_test['hour'] = pd.to_datetime(X_test['datetime']).dt.hour\n",
        "\n",
        "X_train.drop(['datetime','count','casual', 'registered'],axis=1, inplace=True) #'casual', 'registered'는 train과 test수 맞춰주기위\n",
        "\n",
        "a = X_test['datetime']\n",
        "X_test.drop('datetime',axis=1, inplace=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 1234)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "model_rf = RandomForestRegressor()\n",
        "model_rf.fit(X_tr,y_tr)\n",
        "pred_rf = model_rf.predict(X_val)\n",
        "\n",
        "model_xgb = XGBRegressor()\n",
        "model_xgb.fit(X_tr,y_tr)\n",
        "pred_xgb = model_xgb.predict(X_val)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def rmse(y,y_pred):\n",
        "    return np.sqrt(mean_squared_error(y,y_pred))\n",
        "\n",
        "print(rmse(y_val,pred_rf))\n",
        "print(rmse(y_val,pred_xgb)) #작을수록 좋은 회귀모형\n",
        "\n",
        "pred = model_xgb.predict(X_test)\n",
        "output = pd.DataFrame({'datetime' : a, 'count' : pred})\n",
        "output.to_csv('00000.csv', index = False)"
      ],
      "metadata": {
        "id": "5WwoiTAvh4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3유형 통계 검정\n",
        "- 단일표본 검정\n",
        "\n",
        " * 귀무가설: 정규분포를 따른다.\n",
        " * 정규성 만족\n",
        "    - ttest_1samp(data, 기댓값, alternative='two-sided/greater/less')\n",
        "\n",
        " * 정규서 불만족\n",
        "    - 비모수 검정\n",
        "    - wilcoxon(data - 기댓값, alternatvie='two-sided/greater/less')\n",
        "\n",
        "- 두 독립표본의 검정은 분산이 동일하다는 가설검정 이후에 독립표본 t 검정을 시행한다.\n",
        "\n",
        "- 분산 동일성 검정은 stats모듈의 stats.levene( ) 함수를 사용한다.\n",
        "- 두 독립표본 t 검정\n",
        " * 정규성 검정\n",
        "    - shapiro(data1), shapiro(data2) 따로 진행\n",
        "    - 귀무가설 : 정규분포를 따른다.\n",
        " * 등분산성 검정\n",
        "     - levene(data1, data2)\n",
        "     - 귀무가설 : 분산이 동일하다.\n",
        "\n",
        " * ​정규성 o/둥분산성 o :\n",
        "     - ttest_ind(data1, data2, eqaul_val=True, alternative='two-sided/greater/less')\n",
        "     - alternative 변수에 greater(우측검정 : m > m0), less(좌측검정: m < m0), two-sided(양측검정 m != m0)\n",
        " * 정규성 o/등분산성 x :\n",
        "     - ttest_ind(data1, data2, eqaul_val=False, alternative='two-sided/greater/less')\n",
        "\n",
        " * 정규성 x:\n",
        "     - 등분산성 검정 없이 바로 비모수 검정\n",
        "     - mannwhitneyu(data1, data2, alternative='greater/less')\n",
        "- 대응표본 검정\n",
        " *정규성 검정\n",
        "  - shapiro(data1-data2)  \n",
        "  - 귀무가설 : 정규분포를 따른다.\n",
        "  - 정규성 만족\n",
        "     - ttest_rel(data1, data2, alternative='greater/less')\n",
        "  - 정규성 불만족\n",
        "    - 비모수 검정\n",
        "    - wilcoxon(data1 - data2, alternative='greater/less')\n",
        "\n",
        "* 중간 정리: 단일표본검정, 대응표본검정 모두 비모수 검정은 wilcoxon 활용(data1 - data2)"
      ],
      "metadata": {
        "id": "TzIovg42jtp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-1 대응표본 t검정\n",
        "주어진 데이터는 고혈압 환자 치료 전후의 혈압이다. 해당 치료가 효과가 있는지 대응(쌍체)표본 t-검정을 진행하시오\n",
        "귀무가설(H0):  𝜇\n",
        "  >= 0\n",
        "대립가설(H1):  𝜇\n",
        "  < 0\n",
        "𝜇\n",
        "  = (치료 후 혈압 - 치료 전 혈압)의 평균\n",
        "유의수준: 0.05\n",
        "𝜇\n",
        " 의 표본평균은?(소수 둘째자리까지 반올림)\n",
        "검정통계량 값은?(소수 넷째자리까지 반올림)\n",
        "p-값은?(소수 넷째자리까지 반올림)\n",
        "가설검정의 결과는? (유의수준 5%)"
      ],
      "metadata": {
        "id": "vZvvX_fyh4Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/high_blood_pressure.csv\")\n",
        "df\n",
        "\n",
        "df['diff'] = df['bp_pre'] - df['bp_post']\n",
        "mu = round(df['diff'].mean(),2)\n",
        "print(mu)\n",
        "\n",
        "from scipy import stats\n",
        "st, pv = stats.ttest_rel(df['bp_pre'], df['bp_post'], alternative='less')\n",
        "print(round(st,4))\n",
        "print(round(pv,4)) # 0.05보다 작으면 귀무가설 기각"
      ],
      "metadata": {
        "id": "wMr1Rzzsh4fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-2 두 독립표본 t검정\n",
        "어떤 특정 약물을 복용한 사람들의 평균 체온이 복용하지 않은 사람들의 평균 체온과 유의미하게 다른지 검정해보려고 합니다.\n",
        "\n",
        "가정:\n",
        "* 약물을 복용한 그룹과 복용하지 않은 그룹의 체온 데이터가 각각 주어져 있다고 가정\n",
        "* 각 그룹의 체온은 정규분포를 따른다고 가정\n",
        "\n",
        "검정통계량, p-value, 검정결과를 출력하시오"
      ],
      "metadata": {
        "id": "vK9chYMChdkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# 가설 설정\n",
        "# H0: 약물을 복용한 그룹과 복용하지 않은 그룹의 평균 체온은 유의미한 차이가 없다.\n",
        "# H1: 약물을 복용한 그룹과 복용하지 않은 그룹의 평균 체온은 유의미한 차이가 있다.\n",
        "\n",
        "# 데이터 수집\n",
        "group1 = [36.8, 36.7, 37.1, 36.9, 37.2, 36.8, 36.9, 37.1, 36.7, 37.1]\n",
        "group2 = [36.5, 36.6, 36.3, 36.6, 36.9, 36.7, 36.7, 36.8, 36.5, 36.7]\n",
        "\n",
        "# 가설검정\n",
        "t_statistic, p_value = stats.ttest_ind(group1, group2)\n",
        "\n",
        "print(\"검정통계량:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# 유의성 검정\n",
        "alpha = 0.05  # 유의수준 설정\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"귀무가설을 기각합니다. 약물을 복용한 그룹과 복용하지 않은 그룹의 평균 체온은 유의미한 차이가 있습니다.\")\n",
        "else:\n",
        "    print(\"귀무가설을 채택합니다. 약물을 복용한 그룹과 복용하지 않은 그룹의 평균 체온은 유의미한 차이가 없습니다.\")"
      ],
      "metadata": {
        "id": "nOuNXSbthdvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-3 단일표본 검정\n",
        "다음은 22명의 학생들이 국어시험에서 받은 점수이다. 학생들의 평균이 75보다 크다고 할 수 있는가?\n",
        "\n",
        "귀무가설(H0): 모평균은 mu와 같다. (μ = mu), 학생들의 평균은 75이다\n",
        "\n",
        "대립가설(H1): 모평균은 mu보다 크다. (μ > mu), 학생들의 평균은 75보다 크다\n",
        "가정:\n",
        "\n",
        "모집단은 정규분포를 따른다.\n",
        "표본의 크기가 충분히 크다.\n",
        "검정통계량, p-value, 검정결과를 출력하시오\n"
      ],
      "metadata": {
        "id": "ySBJKH0whd5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "# 데이터\n",
        "scores = [75, 80, 68, 72, 77, 82, 81, 79, 70, 74, 76, 78, 81, 73, 81, 78, 75, 72, 74, 79, 78, 79]\n",
        "\n",
        "# 모평균 가설검정\n",
        "mu = 75  # 검정할 모평균\n",
        "alpha = 0.05  # 유의수준\n",
        "\n",
        "# t-test를 사용하여 가설 검정\n",
        "t_statistic, p_value = stats.ttest_1samp(scores, mu, alternative='greater')\n",
        "\n",
        "# 결과 출력\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"귀무가설을 기각합니다. 모평균은 75보다 큽니다.\")\n",
        "else:\n",
        "    print(\"귀무가설을 채택합니다. 모평균은 75보다 크지 않습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvGab3pkheEA",
        "outputId": "01c7e06a-4fb9-4b04-a96e-80d14c31226c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t-statistic: 1.765879233231226\n",
            "p-value: 0.04597614747709146\n",
            "귀무가설을 기각합니다. 모평균은 75보다 큽니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-4 anova\n",
        "세 가지 다른 교육 방법(A, B, C)을 사용하여 수험생들의 시험 성적을 개선시키는 효과를 평가하고자 한다. 30명의 학생들을 무작위로 세 그룹으로 배정하여 교육을 실시하였고, 시험을 보고 성적을 측정하였습니다. 다음은 각 그룹의 학생들의 성적 데이터입니다.\n",
        "\n",
        "귀무가설(H0): 세 그룹(A, B, C) 간의 평균 성적 차이가 없다.\n",
        "\n",
        "대립가설(H1 또는 Ha): 세 그룹(A, B, C) 간의 평균 성적 차이가 있다.\n",
        "\n",
        "일원배치법을 수행하여 그룹 간의 평균 성적 차이가 있는지 검정하세요\n",
        "f값 (소수 둘째자리)\n",
        "p값 (소수 여섯째자리)\n",
        "검정결과 출력"
      ],
      "metadata": {
        "id": "D0fnn4IyheOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# 데이터\n",
        "groupA = [85, 92, 78, 88, 83, 90, 76, 84, 92, 87]\n",
        "groupB = [79, 69, 84, 78, 79, 83, 79, 81, 86, 88]\n",
        "groupC = [75, 68, 74, 65, 77, 72, 70, 73, 78, 75]\n",
        "\n",
        "# 일원배치법 수행\n",
        "f_value, p_value = stats.f_oneway(groupA, groupB, groupC)\n",
        "\n",
        "# F-value\n",
        "print(round(f_value,2))\n",
        "\n",
        "# p-value\n",
        "print(format(p_value,'.6f'))\n",
        "\n",
        "alpha = 0.5\n",
        "if p_value < alpha:\n",
        "    print(\"귀무가설 기각,세 그룹(A, B, C) 간의 평균 성적 차이가 있다 \")\n",
        "else:\n",
        "    print(\"귀무가설 채택,세 그룹(A, B, C) 간의 평균 성적 차이가 없다 \")"
      ],
      "metadata": {
        "id": "ff9HZkxzheZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-5 shapiro_wilk\n",
        "12명의 수험생이 빅데이터 분석기사 시험에서 받은 점수이다. Shapiro-Wilk 검정을 사용하여 데이터가 정규 분포를 따르는지 검증하시오\n",
        "\n",
        "귀무 가설(H0): 데이터는 정규 분포를 따른다.\n",
        "\n",
        "대립 가설(H1): 데이터는 정규 분포를 따르지 않는다.\n",
        "\n",
        "Shapiro-Wilk 검정 통계량, p-value, 검증결과를 출력하시오"
      ],
      "metadata": {
        "id": "NJTzsRi1heit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "\n",
        "data = [75, 83, 81, 92, 68, 77, 78, 80, 85, 95, 79, 89]\n",
        "\n",
        "# Shapiro-Wilk 검정 수행\n",
        "statistic, p_value = stats.shapiro(data)\n",
        "\n",
        "# 결과 출력\n",
        "print(\"Shapiro-Wilk 검정 통계량:\", statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# 유의 수준 0.05에서의 검정 결과 확인\n",
        "alpha = 0.05\n",
        "if p_value > alpha:\n",
        "    print(\"귀무 가설을 기각할 수 없다. 데이터는 정규 분포를 따름\")\n",
        "else:\n",
        "    print(\"귀무 가설을 기각한다. 데이터는 정규 분포를 따르지 않음\")"
      ],
      "metadata": {
        "id": "hTSdipD9hevP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-6 correlation\n",
        "iris에서 Sepal Length와 Sepal Width의 상관계수 계산하고 소수 둘째자리까지 출력하시오"
      ],
      "metadata": {
        "id": "BprDZg0Vhe5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# iris 데이터셋 로드\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "\n",
        "# Sepal Length와 Sepal Width의 상관계수 계산\n",
        "corr = df.corr()\n",
        "round(corr.loc['sepal length (cm)','sepal width (cm)'],2)"
      ],
      "metadata": {
        "id": "B-Km2CjnhfEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-7 logit\n",
        "Pclass, Gender, sibsp, parch를 독립변수로 사용하여 로지스틱 회귀모형을 실시하였을 때, parch변수의 계수값은?"
      ],
      "metadata": {
        "id": "xGJDFRO5ZCxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/Titanic.csv\")\n",
        "\n",
        "from statsmodels.formula.api import logit\n",
        "formula = \"Survived ~ Pclass + Gender + SibSp + Parch\"\n",
        "model = logit(formula, data = df).fit()\n",
        "print(model.params)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "Vo2NEGsnZC4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-8 ttest, anova\n",
        "문제: 두 교육 방법의 효과 비교\n",
        "연구자는 두 가지 다른 교육 방법이 학생들의 성적에 미치는 영향을 비교하고자 합니다. 연구자는 무작위로 선발된 20명의 학생들을 두 그룹으로 나누어 한 그룹에는 교육 방법 A를, 다른 그룹에는 교육 방법 B를 적용합니다. 교육이 끝난 후, 두 그룹의 성적을 비교하기 위해 독립 표본 t-검정과 ANOVA F-검정을 실시하려고 합니다.\n",
        "\n",
        "다음은 두 그룹의 성적입니다: 다음의 두 가지 검정을 사용하여 두 교육 방법 간의 성적 차이가 통계적으로 유의한지를 검증하세요\n",
        "\n",
        "독립 표본 t-검정을 실시하여 t 통계량을 구하세요.\n",
        "\n",
        "독립 표본 t-검정을 실시하여 p-값을 구하세요.\n",
        "\n",
        "ANOVA F-검정을 실시하여 F 통계량을 구하세요.\n",
        "\n",
        "ANOVA F-검정을 실시하여 p-값을 구하세요."
      ],
      "metadata": {
        "id": "zbIVdgiWZDLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'A':[77, 75, 82, 80, 81, 83, 84, 76, 75, 87],\n",
        "    'B':[80, 74, 77, 79, 71, 74, 78, 69, 70, 72],\n",
        "})\n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "stat, p_v = stats.ttest_ind(df['A'], df['B'], alternative = 'two-sided' )\n",
        "print(stat, p_v)\n",
        "\n",
        "stat_a, p_v_a = stats.f_oneway(df['A'], df['B'])\n",
        "print(stat_a, p_v_a)"
      ],
      "metadata": {
        "id": "mG8ZuYhPZDkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-9 chisquare\n",
        "카이제곱 적합도 검정\n",
        "고등학교에서는 졸업생들이 선택하는 대학 전공 분야의 선호도가 시간이 지남에 따라 변하지 않는다고 가정합니다. 학교 측은 최근 졸업생들의 전공 선택이 과거와 같은 패턴을 따르는지 알아보기 위해 적합도 검정을 실시하기로 결정했습니다.\n",
        "\n",
        "과거 자료에 따르면 졸업생들이 선택하는 전공의 분포는 다음과 같습니다:\n",
        "\n",
        "인문학: 20% 사회과학: 30% 자연과학: 25% 공학: 15% 기타: 10% 올해 졸업한 학생 200명의 전공 선택 분포는 다음과 같았습니다:\n",
        "\n",
        "인문학: 30명 사회과학: 60명 자연과학: 50명 공학: 40명 기타: 20명 이 데이터를 바탕으로, 졸업생들의 전공 선택 패턴이 과거와 유사한지를 알아보기 위해 카이제곱 적합도 검정을 실시해야 합니다. 유의 수준은 0.05로 설정합니다.\n",
        "\n",
        "검정 통계량?\n",
        "\n",
        "p-value?\n",
        "\n",
        "유의수준 하 귀무가설 기각 또는 채택?"
      ],
      "metadata": {
        "id": "U4Bkkx-dmTYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# 관측된 빈도\n",
        "observed_frequencies = [30, 60, 50,40, 20]\n",
        "\n",
        "# 기대된 빈도\n",
        "expected_frequencies = [200*0.2, 200*0.3, 200*0.25, 200*0.15, 200*0.1]\n",
        "\n",
        "# 카이제곱 검정\n",
        "stat , p_v = stats.chisquare(f_obs = observed_frequencies, f_exp = expected_frequencies)\n",
        "print(\"검정통계량 : \",stat)\n",
        "print(\"pvalue : \", p_v)\n",
        "if p_v < 0.5:\n",
        "    print(\"귀무가설 기각\")\n",
        "else:\n",
        "    print(\"귀무가설 채택\")"
      ],
      "metadata": {
        "id": "ATt57_FbmTsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-10 지지도,신뢰도,향상도\n",
        "'빼빼로'와 '딴짓초코'가 함께 팔린 거래의 지지도를 계산하세요.\n",
        "\n",
        "'빼빼로'가 팔린 거래 중에서 '빼빼로'와 '오징어칩'이 함께 팔린 거래의 신뢰도를 계산하세요.\n",
        "\n",
        "'빼빼로'와 '양조위빵'의 향상도를 계산하세요.\n",
        "\n",
        "* 지지도(A,B): A와 B가 함께 팔린 거래 횟수 / 전체 거래 횟수\n",
        "\n",
        "* 신뢰도(A->B): A와 B가 함께 팔린 거래 횟수 / A가 팔린 거래 횟수\n",
        "\n",
        "* 향상도(A,B): 신뢰도(A->B) / 지지도(B)"
      ],
      "metadata": {
        "id": "dJ2RQIh6mUCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 데이터\n",
        "df = pd.DataFrame({\n",
        "    'transaction': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
        "    '빼빼로': [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
        "    '딴짓초코': [0, 1, 1, 0, 1, 0, 1, 1, 0, 0],\n",
        "    '양조위빵': [1, 0, 0, 1, 1, 1, 0, 0, 1, 0],\n",
        "    '오징어칩': [0, 1, 1, 0, 0, 1, 0, 1, 1, 1],\n",
        "    '초코파이': [1, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
        "})\n",
        "df\n",
        "\n",
        "#지지도\n",
        "def support(x,y):\n",
        "    return len(df[(df[x] == 1) & (df[y] == 1)]) / len(df)\n",
        "#신뢰도\n",
        "def confidence(x,y):\n",
        "    return len(df[(df[x] == 1) & (df[y] == 1)]) / len(df[(df[x] == 1)])\n",
        "#향상도\n",
        "def lift(x,y):\n",
        "    return confidence(x,y)/ (len(df[(df[y] == 1)]) / len(df))\n",
        "\n",
        "print(support('빼빼로','딴짓초코'))\n",
        "print(confidence('빼빼로','오징어칩'))\n",
        "print(lift('빼빼로','양조위빵'))"
      ],
      "metadata": {
        "id": "wSrx4nPHmUOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-11 poisson\n",
        "포아송분포\n",
        "문제: 한 서점에서는 평균적으로 하루에 3명의 고객이 특정 잡지를 구매합니다. 이 데이터는 포아송 분포를 따른다고 가정할 때, 다음 질문에 대한 답을 구하세요.\n",
        "\n",
        "하루에 정확히 5명의 고객이 잡지를 구매할 확률은 얼마입니까? (%로 값을 정수로 입력하시오)\n",
        "하루에 적어도 2명의 고객이 잡지를 구매할 확률은 얼마입니까? (%로 값을 정수로 입력하시오)\n",
        "add Codeadd Markdown\n",
        "포아송 분포의 확률 질량 함수(PMF) image.png\n",
        "\n",
        "λ는 단위 시간(또는 단위 공간)당 평균 발생 횟수이고, k는 특정 시간(또는 공간) 동안의 이벤트 발생 횟수입니다."
      ],
      "metadata": {
        "id": "dWe6x5fCmUb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# 평균 발생 횟수 (하루에 잡지를 구매하는 고객 수)\n",
        "lambda_ = 3\n",
        "\n",
        "# 하루에 정확히 5명의 고객이 잡지를 구매할 확률\n",
        "print(stats.poisson.pmf(5, lambda_))\n",
        "\n",
        "# 하루에 적어도 2명의 고객이 잡지를 구매할 확률\n",
        "print(1 - stats.poisson.cdf(1, lambda_))"
      ],
      "metadata": {
        "id": "ZW396TIcmUma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-12 chi2\n",
        "성별과 시험합격은 독립적인가를 검정하시오!\n",
        "\n",
        "1 검정 통계량?\n",
        "2 p-value?\n",
        "3 귀무가설 기준 (기각/채택)?\n",
        "4 남자의 합격 기대 빈도?"
      ],
      "metadata": {
        "id": "rAwpbdbA7wpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# 데이터 프레임 생성\n",
        "df = pd.DataFrame({'남자': [100, 200],\n",
        "                   '여자': [130, 170]},\n",
        "                  index=['합격', '불합격'])\n",
        "\n",
        "# 데이터 프레임 출력\n",
        "print(df)\n",
        "\n",
        "# 카이제곱 검정 수행\n",
        "statistic, pvalue, dof, expected = stats.chi2_contingency(df)\n",
        "\n",
        "# 결과 출력\n",
        "print(f'검정통계량: {statistic}')\n",
        "print(f'p-value: {pvalue}')\n",
        "if p_v < 0.5 :\n",
        "    print(\"귀무가설 기각\")\n",
        "else:\n",
        "    print(\"귀무가설 채택\")\n",
        "print(f'남자의 합격 기대빈도: {expected[0][0]}')"
      ],
      "metadata": {
        "id": "kXPDy48C7w1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#T3-13 beronulli, binomial\n",
        "## 베르누이 분포와 이항분포**\n",
        "1. [베르누이 분포] 다음 데이터는 100번의 시도에서 각각 성공(1) 또는 실패(0)를 나타냅니다. 이 데이터를 바탕으로 각 시도의 성공 확률을 계산하시오.\n",
        "2. [이항분포] 1번 문제에서 계산한 성공 확률을 사용하여, 100번의 시도 중 정확히 60번 성공할 확률을 계산하시오."
      ],
      "metadata": {
        "id": "d884f-NC7xC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "binom.pmf(k, n, p) 함수는 이항 분포의 확률 질량 함수(Probability Mass Function, PMF)를 계산하는 데 사용됩니다. 이 함수는 이산 확률 분포인 이항 분포에서 특정한 성공 횟수 k가 나타날 확률을 계산합니다. 함수의 각 매개변수는 다음과 같은 의미를 가집니다:\n",
        "\n",
        "k: 관측하고자 하는 성공 횟수입니다.\n",
        "\n",
        "n: 전체 시도 횟수입니다.\n",
        "\n",
        "p: 각 시도에서 성공할 확률입니다."
      ],
      "metadata": {
        "id": "BtjfJXDDAkOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/kaggle/input/bigdatacertificationkr/t3_success.csv\")\n",
        "\n",
        "from scipy import stats\n",
        "# 1. 베르누이 분포: 각 시도의 성공 확률 계산\n",
        "mu = len(df[df['Success'] == 1]) / len(df)\n",
        "# stats.bernoulli(mu)\n",
        "print(\"성공확률 : \", mu)\n",
        "\n",
        "# 2. 이항 분포: 100번의 시도 중 정확히 60번 성공할 확률 계산\n",
        "N = 100 # 시도 횟수\n",
        "K = 60 # 성공 횟수\n",
        "S_60 = stats.binom.pmf(K,N, mu)\n",
        "print(\"60번 성공할 확률 : \", S_60)"
      ],
      "metadata": {
        "id": "9xBHl9Zo7xNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cbShbYP97xeK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWq-7QsN7xoN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}